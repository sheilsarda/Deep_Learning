# -*- coding: utf-8 -*-
"""ESE546HW2 Q5C.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/191UJxa5QOzx0uNT7PorJVnYiSssyKCGE
"""

!pip install tensorflow==1.12.0;

# torch and torchvision imports
import torch
import torchvision
import torch.nn as nn
import torchvision.transforms as transforms
import torch.optim as optim
from torch.autograd import Variable
import tensorflow as tf
import numpy as np
import scipy.misc 
try:
    from StringIO import StringIO  # Python 2.7
except ImportError:
    from io import BytesIO         # Python 3.x

import matplotlib.pyplot as plt

LOG_DIR = './logs'
get_ipython().system_raw(
    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'
    .format(LOG_DIR)
)

!if [ -f ngrok ] ; then echo "Ngrok already installed" ; else wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip > /dev/null 2>&1 && unzip ngrok-stable-linux-amd64.zip > /dev/null 2>&1 ; fi

"""# Tensorboard setup

Go to the link generated by the code to look at the training loss curve, you can add accuracy and other things to the plot. Refer to the recitation 2 code for referance.
"""

get_ipython().system_raw('./ngrok http 6006 &')

! curl -s http://localhost:4040/api/tunnels | python3 -c \
    "import sys, json; print('Tensorboard Link: ' +str(json.load(sys.stdin)['tunnels'][0]['public_url']))"

# Code referenced from https://gist.github.com/gyglim/1f8dfb1b5c82627ae3efcfbbadb9f514
class Logger(object):
    
    def __init__(self, log_dir):
        """Create a summary writer logging to log_dir."""
        self.writer = tf.summary.FileWriter(log_dir)

    def scalar_summary(self, tag, value, step):
        """Log a scalar variable."""
        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])
        self.writer.add_summary(summary, step)

    def image_summary(self, tag, images, step):
        """Log a list of images."""

        img_summaries = []
        for i, img in enumerate(images):
            # Write the image to a string
            try:
                s = StringIO()
            except:
                s = BytesIO()
            scipy.misc.toimage(img).save(s, format="png")

            # Create an Image object
            img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),
                                       height=img.shape[0],
                                       width=img.shape[1])
            # Create a Summary value
            img_summaries.append(tf.Summary.Value(tag='%s/%d' % (tag, i), image=img_sum))

        # Create and write Summary
        summary = tf.Summary(value=img_summaries)
        self.writer.add_summary(summary, step)
        
    def histo_summary(self, tag, values, step, bins=1000):
        """Log a histogram of the tensor of values."""

        # Create a histogram using numpy
        counts, bin_edges = np.histogram(values, bins=bins)

        # Fill the fields of the histogram proto
        hist = tf.HistogramProto()
        hist.min = float(np.min(values))
        hist.max = float(np.max(values))
        hist.num = int(np.prod(values.shape))
        hist.sum = float(np.sum(values))
        hist.sum_squares = float(np.sum(values**2))

        # Drop the start of the first bin
        bin_edges = bin_edges[1:]

        # Add bin edges and counts
        for edge in bin_edges:
            hist.bucket_limit.append(edge)
        for c in counts:
            hist.bucket.append(c)

        # Create and write Summary
        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])
        self.writer.add_summary(summary, step)
        self.writer.flush()



logger = Logger('./logs')
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

"""# Training Loop on CIFAR 10.


 The model currently does not achieve less than 12% validation error, you have to tweak the parameters to get it.
"""

# Reading in the dataset
transform = transforms.Compose(
    [
      transforms.RandomCrop(32, padding=4),
      transforms.RandomHorizontalFlip(),
     transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=16,
                                          shuffle=True)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=16,
                                         shuffle=False)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

# Defining the model
class View(nn.Module):
    def __init__(self,o):
        super().__init__()
        self.o = o

    def forward(self,x):
        return x.view(-1, self.o)
    
class allcnn_t(nn.Module):
    def __init__(self, c1=96, c2= 192):
        super().__init__()
        d = 0.5

        def convbn(ci,co,ksz,s=1,pz=0):
            return nn.Sequential(
                nn.Conv2d(ci,co,ksz,stride=s,padding=pz),
                nn.ReLU(True),
                nn.BatchNorm2d(co))

        self.m = nn.Sequential(
            nn.Dropout(0.2),
            convbn(3,c1,3,1,1),
            convbn(c1,c1,3,1,1),
            convbn(c1,c1,3,2,1),
            nn.Dropout(d),
            convbn(c1,c2,3,1,1),
            convbn(c2,c2,3,1,1),
            convbn(c2,c2,3,2,1),
            nn.Dropout(d),
            convbn(c2,c2,3,1,1),
            convbn(c2,c2,3,1,1),
            convbn(c2,10,1,1),
            nn.AvgPool2d(8),
            View(10))

        print('Num parameters: ', sum([p.numel() for p in self.m.parameters()]))

    def forward(self, x):
        return self.m(x)

# The training loop
def train(net, optimizer, criterion, train_loader, test_loader, epochs, model_name, plot):
    model = net.to(device)
    total_step = len(train_loader)

    loss_values = []
    accuracy_vals = []

    overall_step = 0
    
    for epoch in range(epochs):
        correct = 0
        total = 0
        epoch_loss = 0

        if(epoch == 40):
          for param_group in optimizer.param_groups:
            param_group['lr'] = 0.01
        elif (epoch == 80):
          for param_group in optimizer.param_groups:
            param_group['lr'] = 0.001
                
        for i, (images, labels) in enumerate(train_loader):
            # Move tensors to configured device
            images = images.to(device)
            labels = labels.to(device)
            #Forward Pass
            outputs = model(images)
            loss = criterion(outputs, labels)

            epoch_loss += loss.item()

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            if (i+1) % 1000 == 0:
              print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(
                  epoch+1, epochs, i+1, total_step, loss.item()))
            if plot:
              info = { ('loss_' + model_name): loss.item() }
              
              for tag, value in info.items():
                logger.scalar_summary(tag, value, overall_step+1)
        
        overall_step += 1

        epoch_loss /= len(train_loader)
        print("Epoch loss: " + str(epoch_loss))
        loss_values.append(epoch_loss)
    
    model.eval()
    with torch.no_grad():
        correct = 0
        total = 0
        for i, (images, labels) in enumerate(test_loader):
            images = images.to(device)
            labels = labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            accuracy = 100*(correct / total)        
            accuracy_vals.append(accuracy)

    print('Accuracy of the network on the test images: {} %'.format(accuracy))
  
    return loss_values, accuracy_vals

model = allcnn_t().to(device)

#TODO: Set it as number of epochs states in the question (100)
epochs = 1

#Define the loss function as asked in the question
criterion = nn.CrossEntropyLoss()

#Set parameters as stated in the question
optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.001)

# Training loop called here
loss_values, accuracy_values = train(
    model, optimizer, criterion, trainloader, testloader, epochs, 'cnn', True)

loss_values

# Plot the training and validation losses as a function of the number of epochs
plt.scatter(range(len(loss_values)), loss_values)

# Plot the training and validation errors as a function of the number of epochs
plt.scatter(range(len(accuracy_values)), accuracy_values)



i = 0
limit = 4
f, axarr = plt.subplots(2, limit, figsize=(15,15))

for j, (images, labels) in enumerate(testloader):
  if i < limit:
    images = images.to(device)
    labels = labels.to(device)
    images.requires_grad = True
    
    outputs = model(images)
    loss = criterion(outputs, labels)
    loss.backward()

    dx = images.grad
    _, predicted = torch.max(outputs.data, 1)
    correct = (predicted == labels)
    num_wrong = correct.size()[0] - sum(correct).item()
    if num_wrong >= limit:
      right_ix = []
      wrong_ix = []
      j = 0
      while(len(right_ix) < limit):
        if correct[j] == True:
          right_ix.append(j)
        j+=1
      j = 0
      while(len(wrong_ix) < limit):
        if correct[j] == False:
          wrong_ix.append(j)
        j+= 1
      
      k = 0
      for ix in right_ix:
        R = np.where(dx[ix].cpu().reshape(32, 32, 3) > 0, 1, 0)[ : , : , 0]
        G = np.where(dx[ix].cpu().reshape(32, 32, 3) > 0, 1, 0)[ : , : , 1]
        B = np.where(dx[ix].cpu().reshape(32, 32, 3) > 0, 1, 0)[ : , : , 2] 
        img = (0.3 * R) + (0.59 * G) + (0.11 * B)  
        axarr[0][k].imshow(img, vmin=0, vmax=1, cmap="Greys")
        k += 1
      
      k = 0
      for ix in wrong_ix:
        R = np.where(dx[ix].cpu().reshape(32, 32, 3) > 0, 1, 0)[ : , : , 0]
        G = np.where(dx[ix].cpu().reshape(32, 32, 3) > 0, 1, 0)[ : , : , 1]
        B = np.where(dx[ix].cpu().reshape(32, 32, 3) > 0, 1, 0)[ : , : , 2] 
        img = (0.3 * R) + (0.59 * G) + (0.11 * B)  
        axarr[1][k].imshow(img, vmin=0, vmax=1, cmap="Greys")
        k += 1
  i+= 1



# Plot loss on the perturbed images as a function of the number of steps in the 
# attack, averaged across the 100-image mini-batch

mini_batch_size = 100
eps = 8
num_steps = 5
mini_batch = torch.utils.data.DataLoader(testset, 
                                         batch_size=mini_batch_size,
                                         shuffle=True)

losses = [0] * num_steps
for i, (images, labels) in enumerate(mini_batch):
  if i > 0:
    break
  for x, y in zip(images, labels):
    x = x[None,:,:,:]
    y = torch.tensor([y])
    x = x.to(device)
    x.requires_grad = True
    y = y.to(device)
    for k in range(num_steps):
      outputs = model(x)
      loss = criterion(outputs, y)
      loss.backward()
      dx = x.grad.data.clone()
      x = x.detach()
      x += eps*dx.sign()
      x = x.to(device)
      x.requires_grad = True
      outputs = model(x)
      loss = criterion(outputs, y)
      losses[k] += loss.item()

plt.plot(range(5), losses)



# Compute accuracy of network on 1-step perturbed images
# For every image in validation set, perturb the image
# using a 1-step attack and check the prediction of the
# network

loss_vals = []
accuracy_vals = []
model.eval();

correct = 0
total = 0
for i, (x, y) in enumerate(testloader):
  if i > 0:
    break

  for x, y in zip(images, labels):
    x = x[None,:,:,:]
    y = torch.tensor([y])
    x = x.to(device)
    x.requires_grad = True
    y = y.to(device)
    
    outputs = model(x)
    loss = criterion(outputs, y)
    loss.backward()

    dx = x.grad.data.clone()
    x = x.detach()
    x += eps*dx.sign()
    x = x.to(device)
    x.requires_grad = True
    outputs = model(x)

    _, predicted = torch.max(outputs.data, 1)

    loss = criterion(outputs, y)
    loss_vals.append(loss.item())     

    total += labels.size(0)
    correct += (predicted == y).sum().item()

    accuracy = 100*(correct / total)        
    accuracy_vals.append(accuracy)

print('Accuracy of the network on the test images: {} %'.format(accuracy))

plt.plot(accuracy_vals)

plt.plot(loss_vals)

# How does accuracy on adversarially perturbed images
# compare with accuracy on clean validation set
# ==> The accuracy is much much lower.

